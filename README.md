# Customer Segmentation and Churn Prediction with PySpark

## ğŸ“Œ Overview
This project showcases the use of **Apache Spark (PySpark)** for scalable customer analytics. It implements a full pipeline for:
- ğŸ“ˆ **Customer segmentation** using RFM metrics and K-Means clustering
- ğŸ” **Churn prediction** using Random Forest and Gradient Boosting Trees
The aim is to support **data-driven marketing** and **customer retention strategies** at scale.

## ğŸ—‚ï¸ Dataset
**Source**: [Online Retail (Chen, 2015)](https://archive.ics.uci.edu/ml/datasets/Online+Retail)  
**Description**:  
- Transactional data from a UK-based online retailer (Dec 2010 â€“ Dec 2011)  
- 541,909 rows Ã— 8 variables  
- Focuses on wholesale customers with behavior-based signals

## âš™ï¸ Workflow
1. **Data Preprocessing & Cleaning**
2. **Feature Engineering:**
   - Derivation of RFM (Recency, Frequency, Monetary) metrics
3. **Customer Segmentation:**
   - K-Means Clustering with WCSS and Silhouette Score optimization
4. **Churn Prediction:**
   - Random Forest and Gradient Boosting classifiers
   - Includes hyperparameter tuning and cross-validation

## ğŸ› ï¸ Tools & Technologies
- Apache Spark (PySpark)
- MLlib (for machine learning)
- Google Colab (for orchestration and analysis)

## ğŸ“Š Results
- Achieved **98% classification accuracy** with high AUC â‰ˆ 0.997
- Effective segmentation of customer groups for targeted strategies
- Demonstrated end-to-end scalable modeling on semi-large datasets

## âš ï¸ Challenges
- Long training time (~4 hours) for ensemble models in PySpark on a single machine
- Lack of distributed infrastructure limited speed and experimentation

## ğŸ”­ Future Work
- âš™ï¸ **Distributed Training** using HDFS and Spark clusters to improve scalability
- ğŸ”„ **Real-Time Prediction** via streaming pipelines for up-to-date churn detection
- ğŸ§© **Feature Expansion** to include customer demographics, browsing logs, and interaction metadata
